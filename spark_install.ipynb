{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark install.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yC40UHIKPJEL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/hadoop/blob/main/spark_install.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q64Z8IYb8fr"
      },
      "source": [
        "# Last amended: 15th June, 2021\n",
        "# Myfolder: github/hadoop\n",
        "# Objectives:\n",
        "#             i) Install pyspark on colab\n",
        "#             ii) Install koalas on colab\n",
        "#\n",
        "#\n",
        "# Java 8 install: https://stackoverflow.com/a/58191107\n",
        "# Hadoop install: https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html\n",
        "# Spark install:  https://stackoverflow.com/a/64183749\n",
        "#                 https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuuFSunM_rL2"
      },
      "source": [
        "# Spark Reference API\n",
        "a. [Quickstart](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart.html) <br>\n",
        "b. Dataframe [APIs list](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#dataframe-apis) at a glance<br>\n",
        "c. ALso look at useful [this source code](https://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/functions.html) of functions that has examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vw_quGSgrW"
      },
      "source": [
        "# Full spark install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC40UHIKPJEL"
      },
      "source": [
        "### 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVUrlkidyaE"
      },
      "source": [
        "# 1.0 How to set environment variable\n",
        "import os  \n",
        "import time  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8cVWRNoPOS6"
      },
      "source": [
        "## 2.0 Define some functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfFBQ0FLcolo"
      },
      "source": [
        "#### ssh_install()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgS9HNCyR7C0"
      },
      "source": [
        "# 2.0 Function to install ssh client and sshd (Server)\n",
        "def ssh_install():\n",
        "  print(\"\\n--1. Download and install ssh server----\\n\")\n",
        "  ! sudo apt-get remove openssh-client openssh-server\n",
        "  ! sudo apt install openssh-client openssh-server\n",
        "  \n",
        "  print(\"\\n--2. Restart ssh server----\\n\")\n",
        "  ! service ssh restart"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJNKSScPcsDS"
      },
      "source": [
        "#### Java install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFu84PSR9jR"
      },
      "source": [
        "# 3.0 Function to download and install java 8\n",
        "def install_java():\n",
        "  ! rm -rf /usr/java\n",
        "\n",
        "  print(\"\\n--Download and install Java 8----\\n\")\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null        # install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     # set environment variable\n",
        "\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !update-alternatives --set javac /usr/lib/jvm/java-8-openjdk-amd64/bin/javac\n",
        "  \n",
        "  !mkdir -p /usr/java\n",
        "  ! ln -s \"/usr/lib/jvm/java-8-openjdk-amd64\"  \"/usr/java\"\n",
        "  ! mv \"/usr/java/java-8-openjdk-amd64\"  \"/usr/java/latest\"\n",
        "  \n",
        "  !java -version       #check java version\n",
        "  !javac -version"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y159J8TDc3wS"
      },
      "source": [
        "#### setup ssh passphrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFbfw7n0Pps"
      },
      "source": [
        "# 6.0 Function tp setup ssh passphrase\n",
        "def set_keys():\n",
        "  print(\"\\n---22. Generate SSH keys----\\n\")\n",
        "  ! cd ~ ; pwd \n",
        "  ! cd ~ ; ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa\n",
        "  ! cd ~ ; cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n",
        "  ! cd ~ ; chmod 0600 ~/.ssh/authorized_keys\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M2kWg3dc6FT"
      },
      "source": [
        "#### Set environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRSn9XAV4rsR"
      },
      "source": [
        "# 7.0 Function to set up environmental variables\n",
        "def set_env():\n",
        "  print(\"\\n---23. Set Environment variables----\\n\")\n",
        "  # 'export' command does not work in colab\n",
        "  # https://stackoverflow.com/a/57240319\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\"   \n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WII-UNCzc9qJ"
      },
      "source": [
        "#### function to install prerequisites\n",
        "java and ssh<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1Mi0rHFpkU"
      },
      "source": [
        "# 8.0 Function to call all functions\n",
        "def install_components():\n",
        "  print(\"\\n--Install java----\\n\")\n",
        "  ssh_install()\n",
        "  install_java()  \n",
        "  #set_keys()\n",
        "  set_env()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHJyHMhUdCRZ"
      },
      "source": [
        "## 3.0 Install components\n",
        "Start downloading, install and configure. Takes around 2 minutes<br>\n",
        "Your <u>input *'y'* is required </u>at one place while overwriting earlier ssh keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77YQikvsJiTm",
        "outputId": "99a5517f-6781-49a0-c3a9-77bbda0641ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 9.0 Start installation\n",
        "start = time.time()\n",
        "install_components()\n",
        "end = time.time()\n",
        "print(\"\\n---Time taken----\\n\")\n",
        "print((end- start)/60)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--Install java----\n",
            "\n",
            "\n",
            "--1. Download and install ssh server----\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package 'openssh-server' is not installed, so not removed\n",
            "The following packages will be REMOVED:\n",
            "  openssh-client\n",
            "0 upgraded, 0 newly installed, 1 to remove and 39 not upgraded.\n",
            "After this operation, 4,162 kB disk space will be freed.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Removing openssh-client (1:7.6p1-4ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ncurses-term openssh-sftp-server python3-certifi python3-chardet\n",
            "  python3-idna python3-pkg-resources python3-requests python3-six\n",
            "  python3-urllib3 ssh-import-id\n",
            "Suggested packages:\n",
            "  keychain libpam-ssh monkeysphere ssh-askpass molly-guard rssh ufw\n",
            "  python3-setuptools python3-cryptography python3-openssl python3-socks\n",
            "The following NEW packages will be installed:\n",
            "  ncurses-term openssh-client openssh-server openssh-sftp-server\n",
            "  python3-certifi python3-chardet python3-idna python3-pkg-resources\n",
            "  python3-requests python3-six python3-urllib3 ssh-import-id\n",
            "0 upgraded, 12 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,762 kB of archives.\n",
            "After this operation, 11.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-client amd64 1:7.6p1-4ubuntu0.3 [614 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ncurses-term all 6.1-1ubuntu1.18.04 [248 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-sftp-server amd64 1:7.6p1-4ubuntu0.3 [45.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-server amd64 1:7.6p1-4ubuntu0.3 [333 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-certifi all 2018.1.18-2 [144 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-urllib3 all 1.22-1ubuntu0.18.04.2 [86.2 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-requests all 2.18.4-2ubuntu0.1 [58.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ssh-import-id all 5.7-0ubuntu1.1 [10.9 kB]\n",
            "Fetched 1,762 kB in 2s (1,127 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 12.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package openssh-client.\n",
            "(Reading database ... 160729 files and directories currently installed.)\n",
            "Preparing to unpack .../00-openssh-client_1%3a7.6p1-4ubuntu0.3_amd64.deb ...\n",
            "Unpacking openssh-client (1:7.6p1-4ubuntu0.3) ...\n",
            "Selecting previously unselected package ncurses-term.\n",
            "Preparing to unpack .../01-ncurses-term_6.1-1ubuntu1.18.04_all.deb ...\n",
            "Unpacking ncurses-term (6.1-1ubuntu1.18.04) ...\n",
            "Selecting previously unselected package openssh-sftp-server.\n",
            "Preparing to unpack .../02-openssh-sftp-server_1%3a7.6p1-4ubuntu0.3_amd64.deb ...\n",
            "Unpacking openssh-sftp-server (1:7.6p1-4ubuntu0.3) ...\n",
            "Selecting previously unselected package openssh-server.\n",
            "Preparing to unpack .../03-openssh-server_1%3a7.6p1-4ubuntu0.3_amd64.deb ...\n",
            "Unpacking openssh-server (1:7.6p1-4ubuntu0.3) ...\n",
            "Selecting previously unselected package python3-certifi.\n",
            "Preparing to unpack .../04-python3-certifi_2018.1.18-2_all.deb ...\n",
            "Unpacking python3-certifi (2018.1.18-2) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../05-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-chardet.\n",
            "Preparing to unpack .../06-python3-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python3-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../07-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../08-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-urllib3.\n",
            "Preparing to unpack .../09-python3-urllib3_1.22-1ubuntu0.18.04.2_all.deb ...\n",
            "Unpacking python3-urllib3 (1.22-1ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package python3-requests.\n",
            "Preparing to unpack .../10-python3-requests_2.18.4-2ubuntu0.1_all.deb ...\n",
            "Unpacking python3-requests (2.18.4-2ubuntu0.1) ...\n",
            "Selecting previously unselected package ssh-import-id.\n",
            "Preparing to unpack .../11-ssh-import-id_5.7-0ubuntu1.1_all.deb ...\n",
            "Unpacking ssh-import-id (5.7-0ubuntu1.1) ...\n",
            "Setting up ncurses-term (6.1-1ubuntu1.18.04) ...\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-certifi (2018.1.18-2) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python3-chardet (3.0.4-1) ...\n",
            "Setting up python3-urllib3 (1.22-1ubuntu0.18.04.2) ...\n",
            "Setting up openssh-client (1:7.6p1-4ubuntu0.3) ...\n",
            "Setting up openssh-sftp-server (1:7.6p1-4ubuntu0.3) ...\n",
            "Setting up python3-requests (2.18.4-2ubuntu0.1) ...\n",
            "Setting up ssh-import-id (5.7-0ubuntu1.1) ...\n",
            "Setting up openssh-server (1:7.6p1-4ubuntu0.3) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/ssh/sshd_config with new version\n",
            "Creating SSH2 RSA key; this may take some time ...\n",
            "2048 SHA256:uQmwOMMwlS/I/jwOyvB46trt5qo4+wCNBtEP009DbV8 root@ca9b702654e3 (RSA)\n",
            "Creating SSH2 ECDSA key; this may take some time ...\n",
            "256 SHA256:C1Vy2s6NbDJOX9wdiUxQK7H5EhIWWVYxDQe3Ro6rs+k root@ca9b702654e3 (ECDSA)\n",
            "Creating SSH2 ED25519 key; this may take some time ...\n",
            "256 SHA256:4GZL7d0yOuO60VVTHuJFtqLPiZc/Kk1aq0pzQ6Vsvoo root@ca9b702654e3 (ED25519)\n",
            "Created symlink /etc/systemd/system/sshd.service → /lib/systemd/system/ssh.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ssh.service → /lib/systemd/system/ssh.service.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for systemd (237-3ubuntu10.47) ...\n",
            "\n",
            "--2. Restart ssh server----\n",
            "\n",
            " * Restarting OpenBSD Secure Shell server sshd\n",
            "   ...done.\n",
            "\n",
            "--Download and install Java 8----\n",
            "\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in manual mode\n",
            "openjdk version \"1.8.0_292\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10)\n",
            "OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)\n",
            "javac 1.8.0_292\n",
            "\n",
            "---23. Set Environment variables----\n",
            "\n",
            "\n",
            "---Time taken----\n",
            "\n",
            "0.44740086793899536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBFVWWuafLBL"
      },
      "source": [
        "## 4.0 Install spark\n",
        "koalas will also be installed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyuLCFRJsvW3"
      },
      "source": [
        "### Define functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk3BP0OfYpT1"
      },
      "source": [
        "`findspark`: PySpark isn't on `sys.path` by default, but that doesn't mean it can't be used as a regular library. You can address this by either symlinking pyspark into your site-packages, or adding `pyspark` to `sys.path` at runtime. `findspark` does the latter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opLGqtPRfM_5"
      },
      "source": [
        "# 1.0 Function to download and unzip spark\n",
        "def spark_koalas_install():\n",
        "  print(\"\\n--1.1 Install findspark----\\n\")\n",
        "  !pip install -q findspark\n",
        "\n",
        "  print(\"\\n--1.2 Install databricks Koalas----\\n\")\n",
        "  !pip install koalas\n",
        "\n",
        "  print(\"\\n--1.3 Download Apache tar.gz----\\n\")\n",
        "  ! wget -c https://apachemirror.wuchna.com/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "\n",
        "  print(\"\\n--1.4 Transfer downloaded content and unzip tar.gz----\\n\")\n",
        "  !  mv /content/spark*   /opt/\n",
        "  ! tar -xzf /opt/spark-3.1.2-bin-hadoop3.2.tgz  --directory /opt/\n",
        "\n",
        "  print(\"\\n--1.5 Check folder for files----\\n\")\n",
        "  ! ls -la /opt\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebXfvQ1qiQHz"
      },
      "source": [
        "# 1.1 Function to set environment\n",
        "def set_spark_env():\n",
        "  print(\"\\n---2. Set Environment variables----\\n\")\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "  os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\" \n",
        "  os.environ[\"SPARK_HOME\"] = \"/opt/spark-3.1.2-bin-hadoop3.2\"     \n",
        "  os.environ[\"LD_LIBRARY_PATH\"] += \":/opt/spark-3.1.2-bin-hadoop3.2/lib/native\"\n",
        "  os.environ[\"PATH\"] += \":/opt/spark-3.1.2-bin-hadoop3.2/bin:/opt/spark-3.1.2-bin-hadoop3.2/sbin\"\n",
        "  print(\"\\n---2.1. Check Environment variables----\\n\")\n",
        "  # Check\n",
        "  ! echo $PATH\n",
        "  ! echo $LD_LIBRARY_PATH"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUsZggDHj13U"
      },
      "source": [
        "# 1.2 Function to configure spark \n",
        "def spark_conf():\n",
        "  print(\"\\n---3. Configure spark to access hadoop----\\n\")\n",
        "  !mv /opt/spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh.template  /opt/spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh\n",
        "  #!echo \"HADOOP_CONF_DIR=/opt/hadoop-3.2.2/etc/hadoop/\" >> /opt/spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh\n",
        "  print(\"\\n---3.1 Check ----\\n\")\n",
        "  #!cat /opt/spark-3.1.1-bin-hadoop3.2/conf/spark-env.sh"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7kLbAFLszN3"
      },
      "source": [
        "### Install spark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_eaLhtPktHJ"
      },
      "source": [
        "# 2.0 Call all the three functions\n",
        "def install_spark():\n",
        "  spark_koalas_install()\n",
        "  set_spark_env()\n",
        "  spark_conf()\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaHs1XxRt5z",
        "outputId": "89fdecbe-bed9-495b-e01f-ce1c5c8f12a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.1 \n",
        "install_spark()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--1.1 Install findspark----\n",
            "\n",
            "\n",
            "--1.2 Install databricks Koalas----\n",
            "\n",
            "Collecting koalas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/6f/d0454b8b7a8ac4cd9838f510ceff0d9eb20d64245c4627f425c06ca6b685/koalas-1.8.0-py3-none-any.whl (720kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.1.5)\n",
            "Requirement already satisfied: numpy<1.20.0,>=1.14 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.19.5)\n",
            "Requirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.7/dist-packages (from koalas) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.2->koalas) (1.15.0)\n",
            "Installing collected packages: koalas\n",
            "Successfully installed koalas-1.8.0\n",
            "\n",
            "--1.3 Download Apache tar.gz----\n",
            "\n",
            "--2021-06-15 05:15:07--  https://apachemirror.wuchna.com/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
            "Resolving apachemirror.wuchna.com (apachemirror.wuchna.com)... 143.110.177.196\n",
            "Connecting to apachemirror.wuchna.com (apachemirror.wuchna.com)|143.110.177.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228834641 (218M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.1.2-bin-hadoop3.2.tgz’\n",
            "\n",
            "spark-3.1.2-bin-had 100%[===================>] 218.23M  13.9MB/s    in 18s     \n",
            "\n",
            "2021-06-15 05:15:26 (12.2 MB/s) - ‘spark-3.1.2-bin-hadoop3.2.tgz’ saved [228834641/228834641]\n",
            "\n",
            "\n",
            "--1.4 Transfer downloaded content and unzip tar.gz----\n",
            "\n",
            "\n",
            "--1.5 Check folder for files----\n",
            "\n",
            "total 223492\n",
            "drwxr-xr-x  1 root root      4096 Jun 15 05:15 .\n",
            "drwxr-xr-x  1 root root      4096 Jun 15 05:08 ..\n",
            "drwxr-xr-x  1 root root      4096 Jun  1 13:35 google\n",
            "drwxr-xr-x  4 root root      4096 Jun  1 13:29 nvidia\n",
            "drwxr-xr-x 13 1000 1000      4096 May 24 04:45 spark-3.1.2-bin-hadoop3.2\n",
            "-rw-r--r--  1 root root 228834641 May 24 05:01 spark-3.1.2-bin-hadoop3.2.tgz\n",
            "\n",
            "---2. Set Environment variables----\n",
            "\n",
            "\n",
            "---2.1. Check Environment variables----\n",
            "\n",
            "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/opt/spark-3.1.2-bin-hadoop3.2/bin:/opt/spark-3.1.2-bin-hadoop3.2/sbin\n",
            "/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/spark-3.1.2-bin-hadoop3.2/lib/native\n",
            "\n",
            "---3. Configure spark to access hadoop----\n",
            "\n",
            "\n",
            "---3.1 Check ----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYRPnQhTRdOn"
      },
      "source": [
        "# Call libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiO4shcjRjNO",
        "outputId": "2ccb9940-da72-49f6-c008-5d80a3a4d74b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 3.0 Just call some libraries to test\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time \n",
        "\n",
        "# 3.1 Get spark in sys.path\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# 3.2 Call other spark libraries\n",
        "#     Just to test\n",
        "from pyspark.sql import SparkSession\n",
        "import databricks.koalas as ks\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7lb_6xCwrZm"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6XYg1IGs17n"
      },
      "source": [
        "# Test spark\n",
        "Create spark session (<i>'spark'</i>) and test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISNdxVmMmUVz"
      },
      "source": [
        "# 3.1 Build spark session\n",
        "spark = SparkSession. \\\n",
        "                    builder. \\\n",
        "                    master(\"local[*]\"). \\\n",
        "                    getOrCreate()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVlRiGQJmk58",
        "outputId": "85bf523b-32bd-4245-83fc-fecdb5b5d5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "# 4.0 Pandas DataFrame\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b','', 'c', 'd','d'],\n",
        "        'x2': ['apple','', 'orange','orange', 'peach','','apple','orange'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4, 1, 2],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5, 3.0, 2.0],\n",
        "        'y1': [1, 0, 1, 0, 0, 1, 1, 0],\n",
        "        'y2': ['yes', 'no', 'no','','', 'yes','', 'yes']\n",
        "    })\n",
        "\n",
        "# 4.1\n",
        "pdf"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>apple</td>\n",
              "      <td>1</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>peach</td>\n",
              "      <td>2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c</td>\n",
              "      <td></td>\n",
              "      <td>4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>d</td>\n",
              "      <td>apple</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>d</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  x1      x2  x3   x4  y1   y2\n",
              "0  a   apple   1  2.4   1  yes\n",
              "1  a           1  2.5   0   no\n",
              "2  b  orange   2  3.5   1   no\n",
              "3  b  orange   2  1.4   0     \n",
              "4      peach   2  2.1   0     \n",
              "5  c           4  1.5   1  yes\n",
              "6  d   apple   1  3.0   1     \n",
              "7  d  orange   2  2.0   0  yes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3pSQ7sDmnjt",
        "outputId": "8b533dfc-7b69-40e1-caed-3912d1aea004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 4.2 Transform to Spark DataFrame\n",
        "#     and print\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|      |  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|   |\n",
            "|   | peach|  2|2.1|  0|   |\n",
            "|  c|      |  4|1.5|  1|yes|\n",
            "|  d| apple|  1|3.0|  1|   |\n",
            "|  d|orange|  2|2.0|  0|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTjT6sQYbgz3"
      },
      "source": [
        "############"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn3xhm6LdXvK"
      },
      "source": [
        "# Your experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iBJeLdqddle"
      },
      "source": [
        "# Get existing spark session using builder object\n",
        "abc = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}