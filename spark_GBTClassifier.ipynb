{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Y3vw_quGSgrW",
        "yC40UHIKPJEL",
        "w8cVWRNoPOS6",
        "mfFBQ0FLcolo",
        "IJNKSScPcsDS",
        "Y159J8TDc3wS",
        "7M2kWg3dc6FT",
        "WII-UNCzc9qJ",
        "iHJyHMhUdCRZ",
        "XBFVWWuafLBL",
        "CyuLCFRJsvW3",
        "M7kLbAFLszN3",
        "MYRPnQhTRdOn",
        "iHd3YFPHO1SV",
        "k5Kb-o82T0oQ",
        "Obzrn0jTVslw",
        "L6XYg1IGs17n",
        "QxLQzJD4p81p"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/hadoop/blob/main/spark_GBTClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vw_quGSgrW"
      },
      "source": [
        "# A. Full spark install\n",
        "Installs `pyspark (spark-3.3.2-bin-hadoop3)` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC40UHIKPJEL"
      },
      "source": [
        "### 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVUrlkidyaE"
      },
      "source": [
        "# 1.0 How to set environment variable\n",
        "import os  \n",
        "import time  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8cVWRNoPOS6"
      },
      "source": [
        "## 2.0 Define some functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfFBQ0FLcolo"
      },
      "source": [
        "#### ssh_install()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgS9HNCyR7C0"
      },
      "source": [
        "# 2.0 Function to install ssh client and sshd (Server)\n",
        "def ssh_install():\n",
        "  print(\"\\n--1. Download and install ssh server----\\n\")\n",
        "  ! sudo apt-get remove openssh-client openssh-server\n",
        "  ! sudo apt install openssh-client openssh-server\n",
        "  \n",
        "  print(\"\\n--2. Restart ssh server----\\n\")\n",
        "  ! service ssh restart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJNKSScPcsDS"
      },
      "source": [
        "#### Java install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFu84PSR9jR"
      },
      "source": [
        "# 3.0 Function to download and install java 8\n",
        "def install_java():\n",
        "  ! rm -rf /usr/java\n",
        "\n",
        "  print(\"\\n--Download and install Java 8----\\n\")\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null        # install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     # set environment variable\n",
        "\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !update-alternatives --set javac /usr/lib/jvm/java-8-openjdk-amd64/bin/javac\n",
        "  \n",
        "  !mkdir -p /usr/java\n",
        "  ! ln -s \"/usr/lib/jvm/java-8-openjdk-amd64\"  \"/usr/java\"\n",
        "  ! mv \"/usr/java/java-8-openjdk-amd64\"  \"/usr/java/latest\"\n",
        "  \n",
        "  !java -version       #check java version\n",
        "  !javac -version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y159J8TDc3wS"
      },
      "source": [
        "#### setup ssh passphrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFbfw7n0Pps"
      },
      "source": [
        "# 6.0 Function tp setup ssh passphrase\n",
        "def set_keys():\n",
        "  print(\"\\n---22. Generate SSH keys----\\n\")\n",
        "  ! cd ~ ; pwd \n",
        "  ! cd ~ ; ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa\n",
        "  ! cd ~ ; cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n",
        "  ! cd ~ ; chmod 0600 ~/.ssh/authorized_keys\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M2kWg3dc6FT"
      },
      "source": [
        "#### Set environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRSn9XAV4rsR"
      },
      "source": [
        "# 7.0 Function to set up environmental variables\n",
        "def set_env():\n",
        "  print(\"\\n---23. Set Environment variables----\\n\")\n",
        "  # 'export' command does not work in colab\n",
        "  # https://stackoverflow.com/a/57240319\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\"   \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WII-UNCzc9qJ"
      },
      "source": [
        "#### function to install prerequisites\n",
        "java and ssh<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1Mi0rHFpkU"
      },
      "source": [
        "# 8.0 Function to call all functions\n",
        "def install_components():\n",
        "  print(\"\\n--Install java----\\n\")\n",
        "  ssh_install()\n",
        "  install_java()  \n",
        "  #set_keys()\n",
        "  set_env()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHJyHMhUdCRZ"
      },
      "source": [
        "## 3.0 Install components\n",
        "Start downloading, install and configure. Takes around 2 minutes<br>\n",
        "Your <u>input *'y'* is required </u>at one place while overwriting earlier ssh keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77YQikvsJiTm",
        "outputId": "8affca14-7b41-4a45-ad68-f39ff9f88b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 9.0 Start installation\n",
        "start = time.time()\n",
        "install_components()\n",
        "end = time.time()\n",
        "print(\"\\n---Time taken----\\n\")\n",
        "print((end- start)/60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--Install java----\n",
            "\n",
            "\n",
            "--1. Download and install ssh server----\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libboost-atomic-dev libboost-atomic1.71-dev libboost-atomic1.71.0\n",
            "  libboost-chrono-dev libboost-chrono1.71-dev libboost-chrono1.71.0\n",
            "  libboost-container-dev libboost-container1.71-dev libboost-container1.71.0\n",
            "  libboost-context-dev libboost-context1.71-dev libboost-context1.71.0\n",
            "  libboost-coroutine-dev libboost-coroutine1.71-dev libboost-coroutine1.71.0\n",
            "  libboost-date-time-dev libboost-date-time1.71-dev libboost-date-time1.71.0\n",
            "  libboost-exception-dev libboost-exception1.71-dev libboost-fiber-dev\n",
            "  libboost-fiber1.71-dev libboost-fiber1.71.0 libboost-filesystem-dev\n",
            "  libboost-filesystem1.71-dev libboost-filesystem1.71.0 libboost-graph-dev\n",
            "  libboost-graph-parallel-dev libboost-graph-parallel1.71-dev\n",
            "  libboost-graph-parallel1.71.0 libboost-graph1.71-dev libboost-graph1.71.0\n",
            "  libboost-iostreams-dev libboost-iostreams1.71-dev libboost-locale-dev\n",
            "  libboost-locale1.71-dev libboost-locale1.71.0 libboost-log-dev\n",
            "  libboost-log1.71-dev libboost-log1.71.0 libboost-math-dev\n",
            "  libboost-math1.71-dev libboost-math1.71.0 libboost-mpi1.71.0\n",
            "  libboost-numpy-dev libboost-numpy1.71-dev libboost-numpy1.71.0\n",
            "  libboost-program-options-dev libboost-program-options1.71-dev\n",
            "  libboost-program-options1.71.0 libboost-python-dev libboost-python1.71-dev\n",
            "  libboost-python1.71.0 libboost-random-dev libboost-random1.71-dev\n",
            "  libboost-random1.71.0 libboost-regex-dev libboost-regex1.71-dev\n",
            "  libboost-regex1.71.0 libboost-serialization-dev\n",
            "  libboost-serialization1.71-dev libboost-serialization1.71.0\n",
            "  libboost-stacktrace-dev libboost-stacktrace1.71-dev\n",
            "  libboost-stacktrace1.71.0 libboost-system-dev libboost-system1.71-dev\n",
            "  libboost-system1.71.0 libboost-test-dev libboost-test1.71-dev\n",
            "  libboost-test1.71.0 libboost-thread-dev libboost-thread1.71-dev\n",
            "  libboost-timer-dev libboost-timer1.71-dev libboost-timer1.71.0\n",
            "  libboost-tools-dev libboost-type-erasure-dev libboost-type-erasure1.71-dev\n",
            "  libboost-type-erasure1.71.0 libboost-wave-dev libboost-wave1.71-dev\n",
            "  libboost-wave1.71.0 libboost1.71-tools-dev libcbor0.6 libevent-dev\n",
            "  libevent-extra-2.1-7 libevent-openssl-2.1-7 libfido2-1 libhwloc-dev\n",
            "  libibverbs-dev libnl-3-dev libnl-route-3-dev libnuma-dev ncurses-term\n",
            "  openmpi-common python3-dev python3-distro python3-distutils python3-lib2to3\n",
            "  python3.8-dev\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following packages will be REMOVED:\n",
            "  openssh-client openssh-server openssh-sftp-server ssh-import-id\n",
            "0 upgraded, 0 newly installed, 4 to remove and 24 not upgraded.\n",
            "After this operation, 5,942 kB disk space will be freed.\n",
            "(Reading database ... 124761 files and directories currently installed.)\n",
            "Removing openssh-server (1:8.2p1-4ubuntu0.5) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of stop.\n",
            "Removing openssh-sftp-server (1:8.2p1-4ubuntu0.5) ...\n",
            "Removing ssh-import-id (5.10-0ubuntu1) ...\n",
            "Removing openssh-client (1:8.2p1-4ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libboost-atomic-dev libboost-atomic1.71-dev libboost-atomic1.71.0\n",
            "  libboost-chrono-dev libboost-chrono1.71-dev libboost-chrono1.71.0\n",
            "  libboost-container-dev libboost-container1.71-dev libboost-container1.71.0\n",
            "  libboost-context-dev libboost-context1.71-dev libboost-context1.71.0\n",
            "  libboost-coroutine-dev libboost-coroutine1.71-dev libboost-coroutine1.71.0\n",
            "  libboost-date-time-dev libboost-date-time1.71-dev libboost-date-time1.71.0\n",
            "  libboost-exception-dev libboost-exception1.71-dev libboost-fiber-dev\n",
            "  libboost-fiber1.71-dev libboost-fiber1.71.0 libboost-filesystem-dev\n",
            "  libboost-filesystem1.71-dev libboost-filesystem1.71.0 libboost-graph-dev\n",
            "  libboost-graph-parallel-dev libboost-graph-parallel1.71-dev\n",
            "  libboost-graph-parallel1.71.0 libboost-graph1.71-dev libboost-graph1.71.0\n",
            "  libboost-iostreams-dev libboost-iostreams1.71-dev libboost-locale-dev\n",
            "  libboost-locale1.71-dev libboost-locale1.71.0 libboost-log-dev\n",
            "  libboost-log1.71-dev libboost-log1.71.0 libboost-math-dev\n",
            "  libboost-math1.71-dev libboost-math1.71.0 libboost-mpi1.71.0\n",
            "  libboost-numpy-dev libboost-numpy1.71-dev libboost-numpy1.71.0\n",
            "  libboost-program-options-dev libboost-program-options1.71-dev\n",
            "  libboost-program-options1.71.0 libboost-python-dev libboost-python1.71-dev\n",
            "  libboost-python1.71.0 libboost-random-dev libboost-random1.71-dev\n",
            "  libboost-random1.71.0 libboost-regex-dev libboost-regex1.71-dev\n",
            "  libboost-regex1.71.0 libboost-serialization-dev\n",
            "  libboost-serialization1.71-dev libboost-serialization1.71.0\n",
            "  libboost-stacktrace-dev libboost-stacktrace1.71-dev\n",
            "  libboost-stacktrace1.71.0 libboost-system-dev libboost-system1.71-dev\n",
            "  libboost-system1.71.0 libboost-test-dev libboost-test1.71-dev\n",
            "  libboost-test1.71.0 libboost-thread-dev libboost-thread1.71-dev\n",
            "  libboost-timer-dev libboost-timer1.71-dev libboost-timer1.71.0\n",
            "  libboost-tools-dev libboost-type-erasure-dev libboost-type-erasure1.71-dev\n",
            "  libboost-type-erasure1.71.0 libboost-wave-dev libboost-wave1.71-dev\n",
            "  libboost-wave1.71.0 libboost1.71-tools-dev libevent-dev libevent-extra-2.1-7\n",
            "  libevent-openssl-2.1-7 libhwloc-dev libibverbs-dev libnl-3-dev\n",
            "  libnl-route-3-dev libnuma-dev openmpi-common python3-dev python3-distutils\n",
            "  python3-lib2to3 python3.8-dev\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  openssh-sftp-server ssh-import-id\n",
            "Suggested packages:\n",
            "  keychain libpam-ssh monkeysphere ssh-askpass molly-guard ufw\n",
            "The following NEW packages will be installed:\n",
            "  openssh-client openssh-server openssh-sftp-server ssh-import-id\n",
            "0 upgraded, 4 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 1,109 kB of archives.\n",
            "After this operation, 5,942 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 openssh-client amd64 1:8.2p1-4ubuntu0.5 [671 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 openssh-sftp-server amd64 1:8.2p1-4ubuntu0.5 [51.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 openssh-server amd64 1:8.2p1-4ubuntu0.5 [377 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 ssh-import-id all 5.10-0ubuntu1 [10.0 kB]\n",
            "Fetched 1,109 kB in 1s (1,232 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package openssh-client.\n",
            "(Reading database ... 124675 files and directories currently installed.)\n",
            "Preparing to unpack .../openssh-client_1%3a8.2p1-4ubuntu0.5_amd64.deb ...\n",
            "Unpacking openssh-client (1:8.2p1-4ubuntu0.5) ...\n",
            "Selecting previously unselected package openssh-sftp-server.\n",
            "Preparing to unpack .../openssh-sftp-server_1%3a8.2p1-4ubuntu0.5_amd64.deb ...\n",
            "Unpacking openssh-sftp-server (1:8.2p1-4ubuntu0.5) ...\n",
            "Selecting previously unselected package openssh-server.\n",
            "Preparing to unpack .../openssh-server_1%3a8.2p1-4ubuntu0.5_amd64.deb ...\n",
            "Unpacking openssh-server (1:8.2p1-4ubuntu0.5) ...\n",
            "Selecting previously unselected package ssh-import-id.\n",
            "Preparing to unpack .../ssh-import-id_5.10-0ubuntu1_all.deb ...\n",
            "Unpacking ssh-import-id (5.10-0ubuntu1) ...\n",
            "Setting up openssh-client (1:8.2p1-4ubuntu0.5) ...\n",
            "Setting up ssh-import-id (5.10-0ubuntu1) ...\n",
            "Setting up openssh-sftp-server (1:8.2p1-4ubuntu0.5) ...\n",
            "Setting up openssh-server (1:8.2p1-4ubuntu0.5) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of restart.\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for systemd (245.4-4ubuntu3.20) ...\n",
            "\n",
            "--2. Restart ssh server----\n",
            "\n",
            " * Restarting OpenBSD Secure Shell server sshd\n",
            "   ...done.\n",
            "\n",
            "--Download and install Java 8----\n",
            "\n",
            "openjdk version \"1.8.0_362\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_362-8u362-ga-0ubuntu1~20.04.1-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.362-b09, mixed mode)\n",
            "javac 1.8.0_362\n",
            "\n",
            "---23. Set Environment variables----\n",
            "\n",
            "\n",
            "---Time taken----\n",
            "\n",
            "0.23619796832402548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBFVWWuafLBL"
      },
      "source": [
        "## 4.0 Install spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyuLCFRJsvW3"
      },
      "source": [
        "### Define functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk3BP0OfYpT1"
      },
      "source": [
        "`findspark`: PySpark isn't on `sys.path` by default, but that doesn't mean it can't be used as a regular library. You can address this by either symlinking pyspark into your site-packages, or adding `pyspark` to `sys.path` at runtime. `findspark` does the latter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opLGqtPRfM_5"
      },
      "source": [
        "# 1.0 Function to download and unzip spark\n",
        "def spark_koalas_install():\n",
        "  print(\"\\n--1.1 Install findspark----\\n\")\n",
        "  !pip install -q findspark\n",
        "\n",
        "  #print(\"\\n--1.2 Install databricks Koalas----\\n\")\n",
        "  #!pip install koalas\n",
        "  \n",
        "  # This download link NEEDS TO BE CHECKED AGAIN\n",
        "  print(\"\\n--1.3 Download Apache tar.gz----\\n\")\n",
        "            \n",
        "  ! wget -c https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz \n",
        "\n",
        "  print(\"\\n--1.4 Transfer downloaded content and unzip tar.gz----\\n\")\n",
        "  !  mv /content/spark*   /opt/\n",
        "  ! tar -xzf /opt/spark-3.3.2-bin-hadoop3.tgz  --directory /opt/\n",
        "\n",
        "  print(\"\\n--1.5 Check folder for files----\\n\")\n",
        "  ! ls -la /opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebXfvQ1qiQHz"
      },
      "source": [
        "# 1.1 Function to set environment\n",
        "def set_spark_env():\n",
        "  print(\"\\n---2. Set Environment variables----\\n\")\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "  os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\" \n",
        "  os.environ[\"SPARK_HOME\"] = \"/opt/spark-3.3.2-bin-hadoop3\" \n",
        "  os.environ[\"SPARK_CONF_DIR\"] = \"/opt/spark-3.3.2-bin-hadoop3/conf\"     \n",
        "  os.environ[\"LD_LIBRARY_PATH\"] += \":/opt/spark-3.3.2-bin-hadoop3/lib/native\"\n",
        "  os.environ[\"PATH\"] += \":/opt/spark-3.3.2-bin-hadoop3/bin:/opt/spark-3.3.2-bin-hadoop3/sbin\"\n",
        "  print(\"\\n---2.1. Check Environment variables----\\n\")\n",
        "  # Check\n",
        "  ! echo $PATH\n",
        "  ! echo $LD_LIBRARY_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUsZggDHj13U"
      },
      "source": [
        "# 1.2 Function to configure spark \n",
        "def spark_conf():\n",
        "  print(\"\\n---3. Configure spark to access hadoop----\\n\")\n",
        "  !mv /opt/spark-3.3.2-bin-hadoop3/conf/spark-env.sh.template  /opt/spark-3.3.2-bin-hadoop3/conf/spark-env.sh\n",
        "  #!echo \"HADOOP_CONF_DIR=/opt/hadoop-3.2.2/etc/hadoop/\" >> /opt/spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh\n",
        "  print(\"\\n---3.1 Check ----\\n\")\n",
        "  #!cat /opt/spark-3.1.1-bin-hadoop3.2/conf/spark-env.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7kLbAFLszN3"
      },
      "source": [
        "### Install spark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_eaLhtPktHJ"
      },
      "source": [
        "# 2.0 Call all the three functions\n",
        "def install_spark():\n",
        "  spark_koalas_install()\n",
        "  set_spark_env()\n",
        "  spark_conf()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaHs1XxRt5z",
        "outputId": "341b31fa-595c-4dda-a220-6a2f05ce83b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.1 \n",
        "install_spark()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--1.1 Install findspark----\n",
            "\n",
            "\n",
            "--1.3 Download Apache tar.gz----\n",
            "\n",
            "--2023-04-08 16:18:13--  https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 299360284 (285M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.3.2-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.3.2-bin-had 100%[===================>] 285.49M   179MB/s    in 1.6s    \n",
            "\n",
            "2023-04-08 16:18:15 (179 MB/s) - ‘spark-3.3.2-bin-hadoop3.tgz’ saved [299360284/299360284]\n",
            "\n",
            "\n",
            "--1.4 Transfer downloaded content and unzip tar.gz----\n",
            "\n",
            "\n",
            "--1.5 Check folder for files----\n",
            "\n",
            "total 292368\n",
            "drwxr-xr-x  1 root root      4096 Apr  8 16:18 .\n",
            "drwxr-xr-x  1 root root      4096 Apr  8 16:12 ..\n",
            "drwxr-xr-x  1 root root      4096 Apr  6 13:56 google\n",
            "drwxr-xr-x  1 root root      4096 Feb  2 05:25 nvidia\n",
            "drwxr-xr-x 13  501 1000      4096 Feb 10 20:40 spark-3.3.2-bin-hadoop3\n",
            "-rw-r--r--  1 root root 299360284 Feb 10 21:28 spark-3.3.2-bin-hadoop3.tgz\n",
            "\n",
            "---2. Set Environment variables----\n",
            "\n",
            "\n",
            "---2.1. Check Environment variables----\n",
            "\n",
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/spark-3.3.2-bin-hadoop3/bin:/opt/spark-3.3.2-bin-hadoop3/sbin:/opt/spark-3.3.2-bin-hadoop3/bin:/opt/spark-3.3.2-bin-hadoop3/sbin\n",
            "/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/spark-3.3.2-bin-hadoop3/lib/native:/opt/spark-3.3.2-bin-hadoop3/lib/native\n",
            "\n",
            "---3. Configure spark to access hadoop----\n",
            "\n",
            "\n",
            "---3.1 Check ----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYRPnQhTRdOn"
      },
      "source": [
        "# B. Call libraries\n",
        "We do not import `pandas` but `pyspark.pandas` as `ps`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiO4shcjRjNO"
      },
      "source": [
        "# 3.0 Just call some libraries to test\n",
        "import numpy as np\n",
        "import os\n",
        "import time \n",
        "\n",
        "# 3.1 Get spark in sys.path\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# 3.2 Call other spark libraries\n",
        "#     Just to test\n",
        "import pyspark.pandas as ps\n",
        "from pyspark.sql import SparkSession\n",
        "#import databricks.koalas as ks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7lb_6xCwrZm"
      },
      "source": [
        "# 3.3\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCOPgKGO60_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e2e4ec-f0ee-4108-8270-e0eee4e6a8df"
      },
      "source": [
        "# 3.4 Increase cell width to display wide columnar output\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHd3YFPHO1SV"
      },
      "source": [
        "# C. Build spark session\n",
        "You can modify spark driver/executor memory here<br>\n",
        "`SparkSession` name is `spark`<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Kb-o82T0oQ"
      },
      "source": [
        "## Modifying spark configuraion\n",
        "Increase driver and executor memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M6d5xfNJSwx",
        "outputId": "7073de6c-f296-47bd-c63c-1518e8e71bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 4.0 Check template file\n",
        "! cat /opt/spark-3.3.2-bin-hadoop3/conf/spark-defaults.conf.template"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#\n",
            "# Licensed to the Apache Software Foundation (ASF) under one or more\n",
            "# contributor license agreements.  See the NOTICE file distributed with\n",
            "# this work for additional information regarding copyright ownership.\n",
            "# The ASF licenses this file to You under the Apache License, Version 2.0\n",
            "# (the \"License\"); you may not use this file except in compliance with\n",
            "# the License.  You may obtain a copy of the License at\n",
            "#\n",
            "#    http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "# Unless required by applicable law or agreed to in writing, software\n",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "# See the License for the specific language governing permissions and\n",
            "# limitations under the License.\n",
            "#\n",
            "\n",
            "# Default system properties included when running spark-submit.\n",
            "# This is useful for setting default environmental settings.\n",
            "\n",
            "# Example:\n",
            "# spark.master                     spark://master:7077\n",
            "# spark.eventLog.enabled           true\n",
            "# spark.eventLog.dir               hdfs://namenode:8021/directory\n",
            "# spark.serializer                 org.apache.spark.serializer.KryoSerializer\n",
            "# spark.driver.memory              5g\n",
            "# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXEkJxzyNYn4"
      },
      "source": [
        "# 4.1 Create spark-defaults.conf \n",
        "! cp /opt/spark-3.3.2-bin-hadoop3/conf/spark-defaults.conf.template  /opt/spark-3.3.2-bin-hadoop3/conf/spark-defaults.conf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZD3i2MXNacY"
      },
      "source": [
        "# 4.2 Amend properties\n",
        "! echo \"spark.driver.memory 6g\" >> /opt/spark-3.3.2-bin-hadoop3/conf/spark-defaults.conf\n",
        "! echo \"spark.executor.memory 3g\" >> /opt/spark-3.3.2-bin-hadoop3/conf/spark-defaults.conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtFbJ5UEObIg",
        "outputId": "f8c7d279-9d78-4e28-95b0-1ebb4c1e72dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 4.3 Check now\n",
        "! cat /opt/spark-3.3.2-bin-hadoop3/conf/spark-defaults.conf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#\n",
            "# Licensed to the Apache Software Foundation (ASF) under one or more\n",
            "# contributor license agreements.  See the NOTICE file distributed with\n",
            "# this work for additional information regarding copyright ownership.\n",
            "# The ASF licenses this file to You under the Apache License, Version 2.0\n",
            "# (the \"License\"); you may not use this file except in compliance with\n",
            "# the License.  You may obtain a copy of the License at\n",
            "#\n",
            "#    http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "# Unless required by applicable law or agreed to in writing, software\n",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "# See the License for the specific language governing permissions and\n",
            "# limitations under the License.\n",
            "#\n",
            "\n",
            "# Default system properties included when running spark-submit.\n",
            "# This is useful for setting default environmental settings.\n",
            "\n",
            "# Example:\n",
            "# spark.master                     spark://master:7077\n",
            "# spark.eventLog.enabled           true\n",
            "# spark.eventLog.dir               hdfs://namenode:8021/directory\n",
            "# spark.serializer                 org.apache.spark.serializer.KryoSerializer\n",
            "# spark.driver.memory              5g\n",
            "# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=\"one two three\"\n",
            "spark.driver.memory 6g\n",
            "spark.executor.memory 3g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obzrn0jTVslw"
      },
      "source": [
        "## Stop and start SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDGr6SWsOqox"
      },
      "source": [
        "# 5.0 Build spark session:\n",
        "# Stop spark, if started\n",
        "#spark.stop()\n",
        "# 5.1 Now start spark\n",
        "spark = SparkSession. \\\n",
        "                    builder. \\\n",
        "                    master(\"local[*]\"). \\\n",
        "                    appName(\"myexpt\"). \\\n",
        "                    getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFOjGwWiaNZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0152971-071f-401d-a3c8-2f29490703af"
      },
      "source": [
        "sc = spark.sparkContext\n",
        "spark.sparkContext.getConf().getAll()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark.driver.extraJavaOptions',\n",
              "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
              " ('spark.executor.memory', '3g'),\n",
              " ('spark.app.name', 'myexpt'),\n",
              " ('spark.driver.port', '37613'),\n",
              " ('spark.executor.id', 'driver'),\n",
              " ('spark.sql.warehouse.dir', 'file:/content/spark-warehouse'),\n",
              " ('spark.app.startTime', '1680952929619'),\n",
              " ('spark.app.submitTime', '1680952929405'),\n",
              " ('spark.app.id', 'local-1680952931417'),\n",
              " ('spark.driver.memory', '6g'),\n",
              " ('spark.rdd.compress', 'True'),\n",
              " ('spark.executor.extraJavaOptions',\n",
              "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
              " ('spark.driver.host', '860b1f1d167b'),\n",
              " ('spark.serializer.objectStreamReset', '100'),\n",
              " ('spark.master', 'local[*]'),\n",
              " ('spark.submit.pyFiles', ''),\n",
              " ('spark.submit.deployMode', 'client'),\n",
              " ('spark.ui.showConsoleProgress', 'true')]"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jimCCywmPJmm",
        "outputId": "5690415c-9833-4845-b9a0-a68d78e598b8"
      },
      "source": [
        "# 5.2\n",
        "print(spark.sparkContext._conf.getAll())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('spark.driver.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'), ('spark.executor.memory', '3g'), ('spark.app.name', 'myexpt'), ('spark.driver.port', '37613'), ('spark.executor.id', 'driver'), ('spark.sql.warehouse.dir', 'file:/content/spark-warehouse'), ('spark.app.startTime', '1680952929619'), ('spark.app.submitTime', '1680952929405'), ('spark.app.id', 'local-1680952931417'), ('spark.driver.memory', '6g'), ('spark.rdd.compress', 'True'), ('spark.executor.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'), ('spark.driver.host', '860b1f1d167b'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.submit.deployMode', 'client'), ('spark.ui.showConsoleProgress', 'true')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6XYg1IGs17n"
      },
      "source": [
        "# D. Test spark\n",
        "Use existing *spark* session to test if spark is working\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVlRiGQJmk58",
        "outputId": "414dbb26-ae9e-4848-8529-81872e9916eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 6.0 pyspark pandas DataFrame\n",
        "pdf = ps.DataFrame({\n",
        "        'x1': ['a','a','b','b','', 'c', 'd','d'],\n",
        "        'x2': ['apple','', 'orange','orange', 'peach','','apple','orange'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4, 1, 2],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5, 3.0, 2.0],\n",
        "        'y1': [1, 0, 1, 0, 0, 1, 1, 0],\n",
        "        'y2': ['yes', 'no', 'no','','', 'yes','', 'yes']\n",
        "    })\n",
        "\n",
        "# 6.1\n",
        "pdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  x1      x2  x3   x4  y1   y2\n",
              "0  a   apple   1  2.4   1  yes\n",
              "1  a           1  2.5   0   no\n",
              "2  b  orange   2  3.5   1   no\n",
              "3  b  orange   2  1.4   0     \n",
              "4      peach   2  2.1   0     \n",
              "5  c           4  1.5   1  yes\n",
              "6  d   apple   1  3.0   1     \n",
              "7  d  orange   2  2.0   0  yes"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>apple</td>\n",
              "      <td>1</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>peach</td>\n",
              "      <td>2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c</td>\n",
              "      <td></td>\n",
              "      <td>4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>d</td>\n",
              "      <td>apple</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>d</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3pSQ7sDmnjt",
        "outputId": "6d0a2c51-c79b-4468-b9a5-94b3560f241f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 6.2 Transform to Spark DataFrame\n",
        "#     and print\n",
        "df = pdf.to_spark()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|      |  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|   |\n",
            "|   | peach|  2|2.1|  0|   |\n",
            "|  c|      |  4|1.5|  1|yes|\n",
            "|  d| apple|  1|3.0|  1|   |\n",
            "|  d|orange|  2|2.0|  0|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/opt/spark-3.3.2-bin-hadoop3/python/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_spark`, the existing index is lost when converting to Spark DataFrame.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTjT6sQYbgz3"
      },
      "source": [
        "############"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxLQzJD4p81p"
      },
      "source": [
        "# E. Some useful functions\n",
        "Execute only if you need. Else, forget it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYwZ4OJfp_tp"
      },
      "source": [
        "# 7.0 Per column how many null values:\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "def null_values(data):\n",
        "  data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8GzRFOIUKoj"
      },
      "source": [
        "# 8.0 Finding mode of a column\n",
        "# Refer StackOverflow: https://stackoverflow.com/a/58279672\n",
        "def mode(df,col):\n",
        "  df.groupby(\"col\").count().orderBy(\"count\", ascending=False).first()[0]\n",
        "\n",
        "# 9.0 Find mode of all columns\n",
        "def mode_cols(df):\n",
        "  [[i,df.groupby(i).count().orderBy(\"count\", ascending=False).first()[0]] for i in df.columns]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbIOI7qpebYo"
      },
      "source": [
        "# 10.0 Value counts\n",
        "def value_counts(df):\n",
        "    for colm in df.columns:\n",
        "        df.groupby(colm).count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQYbaYIBW-BS"
      },
      "source": [
        "# 11.0 Map a string to another\n",
        "# See here: https://stackoverflow.com/a/55026324/3282777\n",
        "# Code not tested\n",
        "# Map a column 'colname' in dataframe 'df'\n",
        "# as follows:\n",
        "#\n",
        "# map_dict= {\n",
        "#            'A': '1',\n",
        "#            'B': '2'\n",
        "#           }\n",
        "\n",
        "def mapping(df,map_dict, colname):\n",
        "  df2 = df.replace(to_replace=map_dict, subset=['yourColName'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn3xhm6LdXvK"
      },
      "source": [
        "# F. Your experiments\n",
        "SparkSession is <i>'spark'</i>. Call all needed libraries. Begin with mounting gdrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ2e6elQoj5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a670b91-3874-430f-c709-5dfd0815c5d6"
      },
      "source": [
        "# 1.0 Mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.0 Call ML libraries:\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler,PCA, OneHotEncoder\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline"
      ],
      "metadata": {
        "id": "YbLsLxAlGkX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1 List path to folder containg csv file. \n",
        "#      Note '/' at the end:\n",
        "\n",
        "pathToFolder = \"/gdrive/MyDrive/Colab_data_files/learning_spark/\""
      ],
      "metadata": {
        "id": "RcIdkz42UAJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Read data:\n",
        "\n",
        "df = spark.read.csv(\n",
        "                 pathToFolder + \"adultdata_modified.csv\",header='true', inferSchema='true'\n",
        "                 )\n"
      ],
      "metadata": {
        "id": "busGA6hBKzvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.0 Explore data:\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvDppKcsJHTL",
        "outputId": "f1f80bf8-d8ed-4c2c-ba1d-cb84aaa53b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|age|       workclass|fnlwgt|   education|education_num|      marital_status|       occupation| relationship|              race|   sex|capital_gain|capital_loss|hours_per_week|native_country|target|\n",
            "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "| 39|       State-gov| 77516|   Bachelors|           13|       Never-married|     Adm-clerical|Not-in-family|             White|  Male|        2174|           0|            40| United-States| <=50K|\n",
            "| 50|Self-emp-not-inc| 83311|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            13| United-States| <=50K|\n",
            "| 38|         Private|215646|     HS-grad|            9|            Divorced|Handlers-cleaners|Not-in-family|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 53|         Private|234721|        11th|            7|  Married-civ-spouse|Handlers-cleaners|      Husband|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 28|         Private|338409|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|         Wife|             Black|Female|           0|           0|            40|          Cuba| <=50K|\n",
            "| 37|         Private|284582|     Masters|           14|  Married-civ-spouse|  Exec-managerial|         Wife|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 49|         Private|160187|         9th|            5|Married-spouse-ab...|    Other-service|Not-in-family|             Black|Female|           0|           0|            16|       Jamaica| <=50K|\n",
            "| 52|Self-emp-not-inc|209642|     HS-grad|            9|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            45| United-States|  >50K|\n",
            "| 31|         Private| 45781|     Masters|           14|       Never-married|   Prof-specialty|Not-in-family|             White|Female|       14084|           0|            50| United-States|  >50K|\n",
            "| 42|         Private|159449|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|        5178|           0|            40| United-States|  >50K|\n",
            "| 37|         Private|280464|Some-college|           10|  Married-civ-spouse|  Exec-managerial|      Husband|             Black|  Male|           0|           0|            80| United-States|  >50K|\n",
            "| 30|       State-gov|141297|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|         India|  >50K|\n",
            "| 23|         Private|122272|   Bachelors|           13|       Never-married|     Adm-clerical|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 32|         Private|205019|  Assoc-acdm|           12|       Never-married|            Sales|Not-in-family|             Black|  Male|           0|           0|            50| United-States| <=50K|\n",
            "| 40|         Private|121772|   Assoc-voc|           11|  Married-civ-spouse|     Craft-repair|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|          null|  >50K|\n",
            "| 34|         Private|245487|     7th-8th|            4|  Married-civ-spouse| Transport-moving|      Husband|Amer-Indian-Eskimo|  Male|           0|           0|            45|        Mexico| <=50K|\n",
            "| 25|Self-emp-not-inc|176756|     HS-grad|            9|       Never-married|  Farming-fishing|    Own-child|             White|  Male|           0|           0|            35| United-States| <=50K|\n",
            "| 32|         Private|186824|     HS-grad|            9|       Never-married|Machine-op-inspct|    Unmarried|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 38|         Private| 28887|        11th|            7|  Married-civ-spouse|            Sales|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n",
            "| 43|Self-emp-not-inc|292175|     Masters|           14|            Divorced|  Exec-managerial|    Unmarried|             White|Female|           0|           0|            45| United-States|  >50K|\n",
            "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark Handling Missing Values\n",
        " [click here](https://www.analyticsvidhya.com/blog/2022/05/data-preprocessing-using-pyspark-handling-missing-values/) <br>"
      ],
      "metadata": {
        "id": "G4aXeLnupn-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2.1 filtering data:\n",
        "df.filter(\"workclass is null\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Nng3YsRFcl",
        "outputId": "61b6b373-3d8b-414b-ee0b-980a98993d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+------+------------+-------------+--------------------+----------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|age|workclass|fnlwgt|   education|education_num|      marital_status|occupation| relationship|              race|   sex|capital_gain|capital_loss|hours_per_week|native_country|target|\n",
            "+---+---------+------+------------+-------------+--------------------+----------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "| 54|     null|180211|Some-college|           10|  Married-civ-spouse|      null|      Husband|Asian-Pac-Islander|  Male|           0|           0|            60|         South|  >50K|\n",
            "| 32|     null|293936|     7th-8th|            4|Married-spouse-ab...|      null|Not-in-family|             White|  Male|           0|           0|            40|          null| <=50K|\n",
            "| 25|     null|200681|Some-college|           10|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 67|     null|212759|        10th|            6|  Married-civ-spouse|      null|      Husband|             White|  Male|           0|           0|             2| United-States| <=50K|\n",
            "| 17|     null|304873|        10th|            6|       Never-married|      null|    Own-child|             White|Female|       34095|           0|            32| United-States| <=50K|\n",
            "| 35|     null|129305|     HS-grad|            9|  Married-civ-spouse|      null|      Husband|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 43|     null|174662|Some-college|           10|            Divorced|      null|Not-in-family|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 52|     null|252903|     HS-grad|            9|            Divorced|      null|Not-in-family|             White|  Male|           0|           0|            45| United-States|  >50K|\n",
            "| 68|     null| 38317|     1st-4th|            2|            Divorced|      null|Not-in-family|             White|Female|           0|           0|            20| United-States| <=50K|\n",
            "| 53|     null|135105|   Bachelors|           13|            Divorced|      null|Not-in-family|             White|Female|           0|           0|            50| United-States| <=50K|\n",
            "| 19|     null|170653|     HS-grad|            9|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            40|         Italy| <=50K|\n",
            "| 64|     null|187656|     1st-4th|            2|            Divorced|      null|Not-in-family|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 60|     null| 24215|        10th|            6|            Divorced|      null|Not-in-family|Amer-Indian-Eskimo|Female|           0|           0|            10| United-States| <=50K|\n",
            "| 20|     null|119156|Some-college|           10|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            20| United-States| <=50K|\n",
            "| 19|     null|218956|Some-college|           10|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            24|        Canada| <=50K|\n",
            "| 39|     null|157443|     Masters|           14|  Married-civ-spouse|      null|         Wife|Asian-Pac-Islander|Female|        3464|           0|            40|          null| <=50K|\n",
            "| 19|     null|860348|Some-college|           10|       Never-married|      null|    Own-child|             Black|Female|           0|           0|            25| United-States| <=50K|\n",
            "| 23|     null|211601|   Assoc-voc|           11|       Never-married|      null|    Own-child|             Black|Female|           0|           0|            15| United-States| <=50K|\n",
            "| 67|     null| 36135|        11th|            7|  Married-civ-spouse|      null|      Husband|             White|  Male|           0|           0|             8| United-States| <=50K|\n",
            "| 30|     null|151989|   Assoc-voc|           11|            Divorced|      null|    Unmarried|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "+---+---------+------+------------+-------------+--------------------+----------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2.2 checking null values:\n",
        "null_values(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZZ9S6aUOmsl",
        "outputId": "f19af684-8beb-4cba-8656-b1f22590dec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------+\n",
            "|age|workclass|fnlwgt|education|education_num|marital_status|occupation|relationship|race|sex|capital_gain|capital_loss|hours_per_week|native_country|target|\n",
            "+---+---------+------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------+\n",
            "|  0|     1836|     0|        0|            0|             0|      1843|           0|   0|  0|           0|           0|             0|           583|     0|\n",
            "+---+---------+------+---------+-------------+--------------+----------+------------+----+---+------------+------------+--------------+--------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2.3 Exploreing data with select:\n",
        "df.createOrReplaceTempView(\"DATA\")\n",
        "spark.sql(\"SELECT * FROM DATA where workclass IS NULL\").show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOYjdwfOpTig",
        "outputId": "2d339aae-b7f1-4a43-a151-68680303941b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+------+------------+-------------+--------------------+----------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|age|workclass|fnlwgt|   education|education_num|      marital_status|occupation| relationship|              race|   sex|capital_gain|capital_loss|hours_per_week|native_country|target|\n",
            "+---+---------+------+------------+-------------+--------------------+----------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "| 54|     null|180211|Some-college|           10|  Married-civ-spouse|      null|      Husband|Asian-Pac-Islander|  Male|           0|           0|            60|         South|  >50K|\n",
            "| 32|     null|293936|     7th-8th|            4|Married-spouse-ab...|      null|Not-in-family|             White|  Male|           0|           0|            40|          null| <=50K|\n",
            "| 25|     null|200681|Some-college|           10|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 67|     null|212759|        10th|            6|  Married-civ-spouse|      null|      Husband|             White|  Male|           0|           0|             2| United-States| <=50K|\n",
            "| 17|     null|304873|        10th|            6|       Never-married|      null|    Own-child|             White|Female|       34095|           0|            32| United-States| <=50K|\n",
            "| 35|     null|129305|     HS-grad|            9|  Married-civ-spouse|      null|      Husband|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 43|     null|174662|Some-college|           10|            Divorced|      null|Not-in-family|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 52|     null|252903|     HS-grad|            9|            Divorced|      null|Not-in-family|             White|  Male|           0|           0|            45| United-States|  >50K|\n",
            "| 68|     null| 38317|     1st-4th|            2|            Divorced|      null|Not-in-family|             White|Female|           0|           0|            20| United-States| <=50K|\n",
            "| 53|     null|135105|   Bachelors|           13|            Divorced|      null|Not-in-family|             White|Female|           0|           0|            50| United-States| <=50K|\n",
            "| 19|     null|170653|     HS-grad|            9|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            40|         Italy| <=50K|\n",
            "| 64|     null|187656|     1st-4th|            2|            Divorced|      null|Not-in-family|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 60|     null| 24215|        10th|            6|            Divorced|      null|Not-in-family|Amer-Indian-Eskimo|Female|           0|           0|            10| United-States| <=50K|\n",
            "| 20|     null|119156|Some-college|           10|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            20| United-States| <=50K|\n",
            "| 19|     null|218956|Some-college|           10|       Never-married|      null|    Own-child|             White|  Male|           0|           0|            24|        Canada| <=50K|\n",
            "| 39|     null|157443|     Masters|           14|  Married-civ-spouse|      null|         Wife|Asian-Pac-Islander|Female|        3464|           0|            40|          null| <=50K|\n",
            "| 19|     null|860348|Some-college|           10|       Never-married|      null|    Own-child|             Black|Female|           0|           0|            25| United-States| <=50K|\n",
            "| 23|     null|211601|   Assoc-voc|           11|       Never-married|      null|    Own-child|             Black|Female|           0|           0|            15| United-States| <=50K|\n",
            "| 67|     null| 36135|        11th|            7|  Married-civ-spouse|      null|      Husband|             White|  Male|           0|           0|             8| United-States| <=50K|\n",
            "| 30|     null|151989|   Assoc-voc|           11|            Divorced|      null|    Unmarried|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "+---+---------+------+------------+-------------+--------------------+----------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4 filling the missing values:\n",
        "df.fillna(value='missing',subset=['workclass','occupation', 'native_country']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJt7YKO_v1Uz",
        "outputId": "8316c0be-496c-418f-deaf-5c2f2b197999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "|age|       workclass|fnlwgt|   education|education_num|      marital_status|       occupation| relationship|              race|   sex|capital_gain|capital_loss|hours_per_week|native_country|target|\n",
            "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "| 39|       State-gov| 77516|   Bachelors|           13|       Never-married|     Adm-clerical|Not-in-family|             White|  Male|        2174|           0|            40| United-States| <=50K|\n",
            "| 50|Self-emp-not-inc| 83311|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            13| United-States| <=50K|\n",
            "| 38|         Private|215646|     HS-grad|            9|            Divorced|Handlers-cleaners|Not-in-family|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 53|         Private|234721|        11th|            7|  Married-civ-spouse|Handlers-cleaners|      Husband|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 28|         Private|338409|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|         Wife|             Black|Female|           0|           0|            40|          Cuba| <=50K|\n",
            "| 37|         Private|284582|     Masters|           14|  Married-civ-spouse|  Exec-managerial|         Wife|             White|Female|           0|           0|            40| United-States| <=50K|\n",
            "| 49|         Private|160187|         9th|            5|Married-spouse-ab...|    Other-service|Not-in-family|             Black|Female|           0|           0|            16|       Jamaica| <=50K|\n",
            "| 52|Self-emp-not-inc|209642|     HS-grad|            9|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            45| United-States|  >50K|\n",
            "| 31|         Private| 45781|     Masters|           14|       Never-married|   Prof-specialty|Not-in-family|             White|Female|       14084|           0|            50| United-States|  >50K|\n",
            "| 42|         Private|159449|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|        5178|           0|            40| United-States|  >50K|\n",
            "| 37|         Private|280464|Some-college|           10|  Married-civ-spouse|  Exec-managerial|      Husband|             Black|  Male|           0|           0|            80| United-States|  >50K|\n",
            "| 30|       State-gov|141297|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|         India|  >50K|\n",
            "| 23|         Private|122272|   Bachelors|           13|       Never-married|     Adm-clerical|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n",
            "| 32|         Private|205019|  Assoc-acdm|           12|       Never-married|            Sales|Not-in-family|             Black|  Male|           0|           0|            50| United-States| <=50K|\n",
            "| 40|         Private|121772|   Assoc-voc|           11|  Married-civ-spouse|     Craft-repair|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|       missing|  >50K|\n",
            "| 34|         Private|245487|     7th-8th|            4|  Married-civ-spouse| Transport-moving|      Husband|Amer-Indian-Eskimo|  Male|           0|           0|            45|        Mexico| <=50K|\n",
            "| 25|Self-emp-not-inc|176756|     HS-grad|            9|       Never-married|  Farming-fishing|    Own-child|             White|  Male|           0|           0|            35| United-States| <=50K|\n",
            "| 32|         Private|186824|     HS-grad|            9|       Never-married|Machine-op-inspct|    Unmarried|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
            "| 38|         Private| 28887|        11th|            7|  Married-civ-spouse|            Sales|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n",
            "| 43|Self-emp-not-inc|292175|     Masters|           14|            Divorced|  Exec-managerial|    Unmarried|             White|Female|           0|           0|            45| United-States|  >50K|\n",
            "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2.7 checking the data types:\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_kgFFWVX6oi",
        "outputId": "4d883076-94d8-4295-a8e5-9fc96e1fbe91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('age', 'int'),\n",
              " ('workclass', 'string'),\n",
              " ('fnlwgt', 'int'),\n",
              " ('education', 'string'),\n",
              " ('education_num', 'int'),\n",
              " ('marital_status', 'string'),\n",
              " ('occupation', 'string'),\n",
              " ('relationship', 'string'),\n",
              " ('race', 'string'),\n",
              " ('sex', 'string'),\n",
              " ('capital_gain', 'int'),\n",
              " ('capital_loss', 'int'),\n",
              " ('hours_per_week', 'int'),\n",
              " ('native_country', 'string'),\n",
              " ('target', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Your cat cols and num cols:\n",
        "\n",
        "catCols = [item[0] for item in df.dtypes if item[1].startswith('string')]\n",
        "#catCols = df.select_dtypes(include = ['object'])\n",
        "numCols = [item[0] for item in df.dtypes if item[1].startswith('int')]\n",
        "\n",
        "print('String features \\n',catCols[-1])\n",
        "print(\"numeric features \\n\",numCols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPCywHuTLbc6",
        "outputId": "5fdb3cdc-8d1a-40fd-8720-5f2a81e89d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String features \n",
            " target\n",
            "numeric features \n",
            " ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.4 What names catCols will have after StringIndexing and OHE:\n",
        "\n",
        "outCols = [i + \"_index\" for i in list(catCols)[:-1]]  # Exclude y\n",
        "outCols\n",
        "oheCols = [i + \"_vec\" for i in list(catCols)[:-1]]\n",
        "oheCols\n",
        "\n",
        "vaCols = oheCols.copy()\n",
        "vaCols.extend(numCols)\n",
        "vaCols"
      ],
      "metadata": {
        "id": "ExC0ftYSLO7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc21422-16fb-49aa-f6a7-f21175299c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['workclass_index',\n",
              " 'education_index',\n",
              " 'marital_status_index',\n",
              " 'occupation_index',\n",
              " 'relationship_index',\n",
              " 'race_index',\n",
              " 'sex_index',\n",
              " 'native_country_index']"
            ]
          },
          "metadata": {},
          "execution_count": 287
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['workclass_vec',\n",
              " 'education_vec',\n",
              " 'marital_status_vec',\n",
              " 'occupation_vec',\n",
              " 'relationship_vec',\n",
              " 'race_vec',\n",
              " 'sex_vec',\n",
              " 'native_country_vec']"
            ]
          },
          "metadata": {},
          "execution_count": 287
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['workclass_vec',\n",
              " 'education_vec',\n",
              " 'marital_status_vec',\n",
              " 'occupation_vec',\n",
              " 'relationship_vec',\n",
              " 'race_vec',\n",
              " 'sex_vec',\n",
              " 'native_country_vec',\n",
              " 'age',\n",
              " 'fnlwgt',\n",
              " 'education_num',\n",
              " 'capital_gain',\n",
              " 'capital_loss',\n",
              " 'hours_per_week']"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.0 Instantiate StringIndexer for multiple columns:\n",
        "\n",
        "indexer = StringIndexer(\n",
        "                        inputCols=catCols[:-1],   # Exclude y\n",
        "                        outputCols=outCols\n",
        "                        )\n",
        "indexer.setHandleInvalid(\"skip\").fit(df).transform(df)\n",
        "\n",
        "encoder = OneHotEncoder(inputCols=outCols,\n",
        "                        outputCols=oheCols)\n",
        "\n",
        "\n",
        "targetindex = StringIndexer(inputCol = 'target',\n",
        "                       outputCol = 'target_index')\n",
        "\n",
        "\n",
        "vectorAssembler = VectorAssembler(\n",
        "                                   inputCols = vaCols,\n",
        "                                   outputCol = 'v_features'\n",
        "                                  )\n",
        "\n",
        "## Applied standard scaler\n",
        "\n",
        "sScaler = StandardScaler(inputCol=\"v_features\", outputCol=\"scaled_features\",\n",
        "                         withMean=True, withStd=True,)\n",
        "\n",
        "##Applied PCA \n",
        "\n",
        "pca =  PCA(k=3, inputCol=\"scaled_features\", outputCol=\"features\")\n",
        "\n",
        "## Instantite gradient boosting classifier object\n",
        "\n",
        "gbc = GBTClassifier(labelCol=\"target_index\",\n",
        "                             maxIter=10\n",
        "                            )"
      ],
      "metadata": {
        "id": "bei-YA22M1Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf70543-4cf0-4d5d-cef6-652c1d52c832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[age: int, workclass: string, fnlwgt: int, education: string, education_num: int, marital_status: string, occupation: string, relationship: string, race: string, sex: string, capital_gain: int, capital_loss: int, hours_per_week: int, native_country: string, target: string, workclass_index: double, education_index: double, marital_status_index: double, occupation_index: double, relationship_index: double, race_index: double, sex_index: double, native_country_index: double]"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Split spark_df into train/test:\n",
        "\n",
        "splits = df.randomSplit([0.7, 0.3])\n",
        "type(splits)   # list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663f4e00-d8db-432a-9658-3bc9403d5e41",
        "id": "o9vH0RNRQDcX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]"
      ],
      "metadata": {
        "id": "YcvBu8ESQDcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are pipelines:\n",
        "See [here](https://spark.apache.org/docs/latest/ml-pipeline.html)"
      ],
      "metadata": {
        "id": "-HxUn6kEpiTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.0 Pipeline now:\n",
        "pipeline = Pipeline(stages= [indexer, encoder, vectorAssembler, targetindex,sScaler,pca, gbc])"
      ],
      "metadata": {
        "id": "C-5E8eKYIWo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 fit pipeline:\n",
        "model_p = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "HbapVJSBJFte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.0 Make predictions:\n",
        "\n",
        "test_df = model_p.transform(test_df)"
      ],
      "metadata": {
        "id": "pNfS4YO-KjB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1:\n",
        "\n",
        "test_df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaMuCohhKtJ7",
        "outputId": "e5719f44-7553-4664-8884-045a853dadab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+------+---------+-------------+--------------+-------------+------------+-----+----+------------+------------+--------------+--------------+------+---------------+---------------+--------------------+----------------+------------------+----------+---------+--------------------+-------------+---------------+------------------+--------------+----------------+-------------+-------------+------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|age|workclass|fnlwgt|education|education_num|marital_status|   occupation|relationship| race| sex|capital_gain|capital_loss|hours_per_week|native_country|target|workclass_index|education_index|marital_status_index|occupation_index|relationship_index|race_index|sex_index|native_country_index|workclass_vec|  education_vec|marital_status_vec|occupation_vec|relationship_vec|     race_vec|      sex_vec|native_country_vec|          v_features|target_index|     scaled_features|            features|       rawPrediction|         probability|prediction|\n",
            "+---+---------+------+---------+-------------+--------------+-------------+------------+-----+----+------------+------------+--------------+--------------+------+---------------+---------------+--------------------+----------------+------------------+----------+---------+--------------------+-------------+---------------+------------------+--------------+----------------+-------------+-------------+------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "| 17|Local-gov| 32124|      9th|            5| Never-married|Other-service|   Own-child|Black|Male|           0|           0|             9| United-States| <=50K|            2.0|           10.0|                 1.0|             5.0|               2.0|       1.0|      0.0|                 0.0|(7,[2],[1.0])|(15,[10],[1.0])|     (6,[1],[1.0])|(13,[5],[1.0])|   (5,[2],[1.0])|(4,[1],[1.0])|(1,[0],[1.0])|    (40,[0],[1.0])|(97,[2,17,23,33,4...|         0.0|[-1.6869813327704...|[-3.5076885993122...|[1.32025167091270...|[0.93342325106781...|       0.0|\n",
            "| 17|Local-gov|191910|     11th|            7| Never-married|        Sales|   Own-child|White|Male|           0|           0|            20| United-States| <=50K|            2.0|            5.0|                 1.0|             4.0|               2.0|       0.0|      0.0|                 0.0|(7,[2],[1.0])| (15,[5],[1.0])|     (6,[1],[1.0])|(13,[4],[1.0])|   (5,[2],[1.0])|(4,[0],[1.0])|(1,[0],[1.0])|    (40,[0],[1.0])|(97,[2,12,23,32,4...|         0.0|[-1.6869813327704...|[-2.2445953955861...|[1.31702844540736...|[0.93302151991377...|       0.0|\n",
            "+---+---------+------+---------+-------------+--------------+-------------+------------+-----+----+------------+------------+--------------+--------------+------+---------------+---------------+--------------------+----------------+------------------+----------+---------+--------------------+-------------+---------------+------------------+--------------+----------------+-------------+-------------+------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2 Evaluate:\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol = 'target_index', metricName = 'areaUnderROC' )"
      ],
      "metadata": {
        "id": "iZ1HPiZgQdjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2.1\n",
        "evaluator.evaluate(test_df)  ## 0.8712789155578531"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43750df3-f740-470d-ec3a-ae9f3f844452",
        "id": "D9s1UqtAQdj0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8712789155578531"
            ]
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Without applying PCA and standard scaler\n"
      ],
      "metadata": {
        "id": "OQ5OWIAtq_f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 Instantiate StringIndexer for multiple columns:\n",
        "\n",
        "indexer = StringIndexer(\n",
        "                        inputCols=catCols[:-1],   # Exclude y\n",
        "                        outputCols=outCols\n",
        "                        )\n",
        "indexer.setHandleInvalid(\"skip\").fit(df).transform(df)\n",
        "\n",
        "encoder = OneHotEncoder(inputCols=outCols,\n",
        "                        outputCols=oheCols)\n",
        "\n",
        "\n",
        "targetindex = StringIndexer(inputCol = 'target',\n",
        "                       outputCol = 'target_index')\n",
        "\n",
        "\n",
        "vectorAssembler = VectorAssembler(\n",
        "                                   inputCols = vaCols,\n",
        "                                   outputCol = 'features'\n",
        "                                  )\n",
        "\n",
        "\n",
        "\n",
        "gbt = GBTClassifier(labelCol=\"target_index\",\n",
        "                             maxIter=10\n",
        "                            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bstc4UKwq-8N",
        "outputId": "49b69c59-8ff5-460f-82a6-7b8c902fca30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[age: int, workclass: string, fnlwgt: int, education: string, education_num: int, marital_status: string, occupation: string, relationship: string, race: string, sex: string, capital_gain: int, capital_loss: int, hours_per_week: int, native_country: string, target: string, workclass_index: double, education_index: double, marital_status_index: double, occupation_index: double, relationship_index: double, race_index: double, sex_index: double, native_country_index: double]"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Split spark_df into train/test:\n",
        "\n",
        "splits = df.randomSplit([0.7, 0.3])\n",
        "type(splits)   # list\n",
        "# 3.2\n",
        "train_df = splits[0]\n",
        "test_df = splits[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY7hx1gfrYSH",
        "outputId": "a46b7e51-60ee-4ffd-9fef-a91d0efb80dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.0 Pipeline now:\n",
        "pipeline = Pipeline(stages= [indexer, encoder, vectorAssembler, targetindex, gbt ])\n",
        "model_p = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "WxK9YINvrglg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = model_p.transform(test_df)\n",
        "# 5.1:\n",
        "\n",
        "test_df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z62B-WbjrnJP",
        "outputId": "96e71fa4-4485-45d6-ed79-582e7943c2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+------+---------+-------------+--------------+-------------+------------+-----+------+------------+------------+--------------+--------------+------+---------------+---------------+--------------------+----------------+------------------+----------+---------+--------------------+-------------+---------------+------------------+--------------+----------------+-------------+-------------+------------------+--------------------+------------+--------------------+--------------------+----------+\n",
            "|age|workclass|fnlwgt|education|education_num|marital_status|   occupation|relationship| race|   sex|capital_gain|capital_loss|hours_per_week|native_country|target|workclass_index|education_index|marital_status_index|occupation_index|relationship_index|race_index|sex_index|native_country_index|workclass_vec|  education_vec|marital_status_vec|occupation_vec|relationship_vec|     race_vec|      sex_vec|native_country_vec|            features|target_index|       rawPrediction|         probability|prediction|\n",
            "+---+---------+------+---------+-------------+--------------+-------------+------------+-----+------+------------+------------+--------------+--------------+------+---------------+---------------+--------------------+----------------+------------------+----------+---------+--------------------+-------------+---------------+------------------+--------------+----------------+-------------+-------------+------------------+--------------------+------------+--------------------+--------------------+----------+\n",
            "| 17|Local-gov| 39815|     10th|            6| Never-married|Other-service|   Own-child|White|Female|           0|           0|            25| United-States| <=50K|            2.0|            7.0|                 1.0|             5.0|               2.0|       0.0|      1.0|                 0.0|(7,[2],[1.0])| (15,[7],[1.0])|     (6,[1],[1.0])|(13,[5],[1.0])|   (5,[2],[1.0])|(4,[0],[1.0])|    (1,[],[])|    (40,[0],[1.0])|(97,[2,14,23,33,4...|         0.0|[1.31223912164747...|[0.93242043904943...|       0.0|\n",
            "| 17|Local-gov|192387|      9th|            5| Never-married|Other-service|   Own-child|White|  Male|           0|           0|            45| United-States| <=50K|            2.0|           10.0|                 1.0|             5.0|               2.0|       0.0|      0.0|                 0.0|(7,[2],[1.0])|(15,[10],[1.0])|     (6,[1],[1.0])|(13,[5],[1.0])|   (5,[2],[1.0])|(4,[0],[1.0])|(1,[0],[1.0])|    (40,[0],[1.0])|(97,[2,17,23,33,4...|         0.0|[1.17793021237645...|[0.91339891944790...|       0.0|\n",
            "+---+---------+------+---------+-------------+--------------+-------------+------------+-----+------+------------+------------+--------------+--------------+------+---------------+---------------+--------------------+----------------+------------------+----------+---------+--------------------+-------------+---------------+------------------+--------------+----------------+-------------+-------------+------------------+--------------------+------------+--------------------+--------------------+----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2 Evaluate:\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol = 'target_index', metricName = 'areaUnderROC' )"
      ],
      "metadata": {
        "id": "rywISgEHrt6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2.1\n",
        "evaluator.evaluate(test_df)  ## 0.9043883553393772"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqqzdbAErzDb",
        "outputId": "fcacb331-4f6e-469c-e2e6-224f0bf659d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9043883553393772"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################ I am done #################3"
      ],
      "metadata": {
        "id": "GPU3rQKspCqp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}