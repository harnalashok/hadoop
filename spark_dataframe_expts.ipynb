{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark_dataframe_expts.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yC40UHIKPJEL",
        "AWahGhSLEBqL",
        "L6XYg1IGs17n",
        "Zn3xhm6LdXvK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/hadoop/blob/main/spark_dataframe_expts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q64Z8IYb8fr"
      },
      "source": [
        "# Last amended: 30th Sep, 2021\n",
        "# Myfolder: github/hadoop\n",
        "# Objectives:\n",
        "#             i) Install pyspark on colab\n",
        "#             ii) Install koalas on colab\n",
        "#\n",
        "#\n",
        "# Java 8 install: https://stackoverflow.com/a/58191107\n",
        "# Hadoop install: https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html\n",
        "# Spark install:  https://stackoverflow.com/a/64183749\n",
        "#                 https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vw_quGSgrW"
      },
      "source": [
        "# Full spark install\n",
        "> At times the download mirror for Apache Spark file `.tgz` is unavailable. If you get an error, please check if the download mirror is OK. <br>\n",
        "> In case you are also changing the spark or hadoop version, same change will have to be made in the spark environment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC40UHIKPJEL"
      },
      "source": [
        "### 1.0 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVUrlkidyaE"
      },
      "source": [
        "# 1.0 How to set environment variable\n",
        "import os  \n",
        "import time  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8cVWRNoPOS6"
      },
      "source": [
        "## 2.0 Define some functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfFBQ0FLcolo"
      },
      "source": [
        "#### ssh_install()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgS9HNCyR7C0"
      },
      "source": [
        "# 2.0 Function to install ssh client and sshd (Server)\n",
        "def ssh_install():\n",
        "  print(\"\\n--1. Download and install ssh server----\\n\")\n",
        "  ! sudo apt-get remove openssh-client openssh-server\n",
        "  ! sudo apt install openssh-client openssh-server\n",
        "  \n",
        "  print(\"\\n--2. Restart ssh server----\\n\")\n",
        "  ! service ssh restart"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJNKSScPcsDS"
      },
      "source": [
        "#### Java install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFu84PSR9jR"
      },
      "source": [
        "# 3.0 Function to download and install java 8\n",
        "def install_java():\n",
        "  ! rm -rf /usr/java\n",
        "\n",
        "  print(\"\\n--Download and install Java 8----\\n\")\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null        # install openjdk\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     # set environment variable\n",
        "\n",
        "  !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "  !update-alternatives --set javac /usr/lib/jvm/java-8-openjdk-amd64/bin/javac\n",
        "  \n",
        "  !mkdir -p /usr/java\n",
        "  ! ln -s \"/usr/lib/jvm/java-8-openjdk-amd64\"  \"/usr/java\"\n",
        "  ! mv \"/usr/java/java-8-openjdk-amd64\"  \"/usr/java/latest\"\n",
        "  \n",
        "  !java -version       #check java version\n",
        "  !javac -version"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y159J8TDc3wS"
      },
      "source": [
        "#### setup ssh passphrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFbfw7n0Pps"
      },
      "source": [
        "# 6.0 Function tp setup ssh passphrase\n",
        "def set_keys():\n",
        "  print(\"\\n---22. Generate SSH keys----\\n\")\n",
        "  ! cd ~ ; pwd \n",
        "  ! cd ~ ; ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa\n",
        "  ! cd ~ ; cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n",
        "  ! cd ~ ; chmod 0600 ~/.ssh/authorized_keys\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M2kWg3dc6FT"
      },
      "source": [
        "#### Set environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRSn9XAV4rsR"
      },
      "source": [
        "# 7.0 Function to set up environmental variables\n",
        "def set_env():\n",
        "  print(\"\\n---23. Set Environment variables----\\n\")\n",
        "  # 'export' command does not work in colab\n",
        "  # https://stackoverflow.com/a/57240319\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
        "  os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\"   \n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WII-UNCzc9qJ"
      },
      "source": [
        "#### function to install prerequisites\n",
        "java and ssh<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1Mi0rHFpkU"
      },
      "source": [
        "# 8.0 Function to call all functions\n",
        "def install_components():\n",
        "  print(\"\\n--Install java----\\n\")\n",
        "  ssh_install()\n",
        "  install_java()  \n",
        "  #set_keys()\n",
        "  set_env()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHJyHMhUdCRZ"
      },
      "source": [
        "## 3.0 Install components\n",
        "Start downloading, install and configure. Takes around 2 minutes<br>\n",
        "Your <u>input *'y'* is required </u>at one place while overwriting earlier ssh keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77YQikvsJiTm"
      },
      "source": [
        "# 9.0 Start installation\n",
        "start = time.time()\n",
        "install_components()\n",
        "end = time.time()\n",
        "print(\"\\n---Time taken----\\n\")\n",
        "print((end- start)/60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBFVWWuafLBL"
      },
      "source": [
        "## 4.0 Install spark\n",
        "koalas will also be installed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyuLCFRJsvW3"
      },
      "source": [
        "### Define functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk3BP0OfYpT1"
      },
      "source": [
        "`findspark`: PySpark isn't on `sys.path` by default, but that doesn't mean it can't be used as a regular library. You can address this by either symlinking pyspark into your site-packages, or adding `pyspark` to `sys.path` at runtime. `findspark` does the latter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opLGqtPRfM_5"
      },
      "source": [
        "# 1.0 Function to download and unzip spark\n",
        "def spark_koalas_install():\n",
        "  print(\"\\n--1.1 Install findspark----\\n\")\n",
        "  !pip install -q findspark\n",
        "\n",
        "  print(\"\\n--1.2 Install databricks Koalas----\\n\")\n",
        "  !pip install koalas\n",
        "\n",
        "  print(\"\\n--1.3 Download Spark Apache tar.gz----\\n\")\n",
        "  #! wget -c https://apachemirror.wuchna.com/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "  ! wget -c https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz \n",
        "\n",
        "  print(\"\\n--1.4 Transfer downloaded content and unzip tar.gz----\\n\")\n",
        "  !  mv /content/spark*   /opt/\n",
        "  ! tar -xzf /opt/spark-3.1.2-bin-hadoop3.2.tgz  --directory /opt/\n",
        "\n",
        "  print(\"\\n--1.5 Check folder for files----\\n\")\n",
        "  ! ls -la /opt\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebXfvQ1qiQHz"
      },
      "source": [
        "# 1.1 Function to set environment\n",
        "def set_spark_env():\n",
        "  print(\"\\n---2. Set Environment variables----\\n\")\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "  os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\" \n",
        "  os.environ[\"SPARK_HOME\"] = \"/opt/spark-3.1.2-bin-hadoop3.2\"     \n",
        "  os.environ[\"LD_LIBRARY_PATH\"] += \":/opt/spark-3.1.2-bin-hadoop3.2/lib/native\"\n",
        "  os.environ[\"PATH\"] += \":/opt/spark-3.1.2-bin-hadoop3.2/bin:/opt/spark-3.1.2-bin-hadoop3.2/sbin\"\n",
        "  print(\"\\n---2.1. Check Environment variables----\\n\")\n",
        "  # Check\n",
        "  ! echo $PATH\n",
        "  ! echo $LD_LIBRARY_PATH"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUsZggDHj13U"
      },
      "source": [
        "# 1.2 Function to configure spark \n",
        "def spark_conf():\n",
        "  print(\"\\n---3. Configure spark to access hadoop----\\n\")\n",
        "  !mv /opt/spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh.template  /opt/spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh\n",
        "  #!echo \"HADOOP_CONF_DIR=/opt/hadoop-3.2.2/etc/hadoop/\" >> /opt/spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh\n",
        "  print(\"\\n---3.1 Check ----\\n\")\n",
        "  #!cat /opt/spark-3.1.1-bin-hadoop3.2/conf/spark-env.sh"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7kLbAFLszN3"
      },
      "source": [
        "### Install spark\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5r-SHEDNFVA"
      },
      "source": [
        "spark_koalas_install()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_eaLhtPktHJ"
      },
      "source": [
        "# 2.0 Call all the three functions\n",
        "def install_spark():\n",
        "  spark_koalas_install()\n",
        "  set_spark_env()\n",
        "  spark_conf()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emaHs1XxRt5z"
      },
      "source": [
        "# 2.1 \n",
        "install_spark()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWahGhSLEBqL"
      },
      "source": [
        "# Create SparkSession\n",
        "Henceforth use 'spark' as SparkSession object<br>\n",
        "For Spark configuration options, see [here](http://spark.apache.org/docs/latest/configuration.html#spark-properties)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYGBgP70EKiJ"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Get spark in sys.path\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#  Build  spark session\n",
        "#     with certain configuration options\n",
        "#     .master => Connect to spark which URL? \"local\" to run locally, \n",
        "#                \"local[4]\" to run locally with 4 cores,\n",
        "#                or \"spark://master:7077\" to run on a Spark standalone cluster.\n",
        "#\n",
        "spark = SparkSession. \\\n",
        "                    builder. \\\n",
        "                    master(\"local[*]\"). \\\n",
        "                    config(\"spark.driver.memory\", \"3g\"). \\\n",
        "                    getOrCreate()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6XYg1IGs17n"
      },
      "source": [
        "# Test spark\n",
        "Create a pandas dataframe and then use 'spark' object to transform it to Spark DataFrame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h-yXLclFiLk"
      },
      "source": [
        "### Call libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1RXFGClfCy"
      },
      "source": [
        "# 3.0 Just call some libraries to test\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 3.1 Call other spark libraries\n",
        "#     Just to test\n",
        "import databricks.koalas as ks\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRcydbfmqzGX"
      },
      "source": [
        "### Understanding SparkSession\n",
        "You can understand more about 'spark' session object using some available methods. <br>\n",
        "For Spark configuration options, see [here](http://spark.apache.org/docs/latest/configuration.html#spark-properties)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhFDaRinqTBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a6b75261-6840-4929-c25f-05ac14708d49"
      },
      "source": [
        "# 3.1.1\n",
        "# Get spark configuration\n",
        "spark.conf.get(\"spark.driver.memory\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3g'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RD05F9IqZOs"
      },
      "source": [
        "# 3.1.2 \n",
        "# Get spark session \n",
        "abc = spark.builder.getOrCreate()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkeUhzdMsDwZ"
      },
      "source": [
        "### Creating spark dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hkt2OyksJAh"
      },
      "source": [
        "#### From pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVlRiGQJmk58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7a87a1c6-aaa5-4b08-96a1-22ac51fbbf79"
      },
      "source": [
        "# 4.0 Pandas DataFrame\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c', 'd','d'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach','apple','orange'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4, 1, 2],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5, 3.0, 2.0],\n",
        "        'y1': [1, 0, 1, 0, 0, 1, 1, 0],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes']\n",
        "    })\n",
        "\n",
        "# 4.1\n",
        "pdf"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>apple</td>\n",
              "      <td>1</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>orange</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>peach</td>\n",
              "      <td>2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c</td>\n",
              "      <td>peach</td>\n",
              "      <td>4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>d</td>\n",
              "      <td>apple</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>d</td>\n",
              "      <td>orange</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  x1      x2  x3   x4  y1   y2\n",
              "0  a   apple   1  2.4   1  yes\n",
              "1  a  orange   1  2.5   0   no\n",
              "2  b  orange   2  3.5   1   no\n",
              "3  b  orange   2  1.4   0  yes\n",
              "4  b   peach   2  2.1   0  yes\n",
              "5  c   peach   4  1.5   1  yes\n",
              "6  d   apple   1  3.0   1   no\n",
              "7  d  orange   2  2.0   0  yes"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3pSQ7sDmnjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9abe41-331f-4b09-fc8c-3db29108bb24"
      },
      "source": [
        "# 4.2 Transform to Spark DataFrame\n",
        "#     and print\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "|  c| peach|  4|1.5|  1|yes|\n",
            "|  d| apple|  1|3.0|  1| no|\n",
            "|  d|orange|  2|2.0|  0|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p91zAEU2qo9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553b37f2-0df6-4a13-a33b-c15bbd1b43c8"
      },
      "source": [
        "df1 = abc.createDataFrame(pdf)\n",
        "df1.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "|  c| peach|  4|1.5|  1|yes|\n",
            "|  d| apple|  1|3.0|  1| no|\n",
            "|  d|orange|  2|2.0|  0|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTjT6sQYbgz3"
      },
      "source": [
        "############"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn3xhm6LdXvK"
      },
      "source": [
        "# Your experiments\n",
        "Once SparkSession is created as above, begin using the session object 'spark', henceforth, OR get a the same object with a new name using `SparkSession.builder.getOrCreate()` as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpTXf5CwFhDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d867ec9-1522-4482-ca0a-4c6390737ad1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4zk5AxcSe6s"
      },
      "source": [
        "pathToFolder = \"/content/drive/MyDrive/healthcare-analytics/breast_cancer_wisconsin/\"\n",
        "pathToFolder1 = \"/content/drive/MyDrive/Colab_data_files/adult/\""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIqjW83OfmMq"
      },
      "source": [
        "# Get existing spark session using builder object\n",
        "abc = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbF3f4b4fm8y"
      },
      "source": [
        "abc.conf.get(\"spark.driver.memory\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrqJj2_rp0mg"
      },
      "source": [
        "df = spark.read.csv(\n",
        "                     pathToFolder+\"breast_cancer.csv\",\n",
        "                     header = True\n",
        "                     )"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FeKt1eruCDI"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8qvNDvUEea-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07458783-5d99-49cc-c383-2b1bd264d133"
      },
      "source": [
        "len(df.columns)\n",
        "df.count()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-zgS_43EqIU"
      },
      "source": [
        "df1 = spark.read.csv(\n",
        "                     pathToFolder1+\"adultdata_modified_na.csv\",\n",
        "                     header = True\n",
        "                     )"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjuUAn92EuC8"
      },
      "source": [
        "df1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duU5VmxDuKfi"
      },
      "source": [
        "df1 = df.sample(fraction = 0.5)\n",
        "df2 = df.sample(fraction = 1.0)  # Shuffle it "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYDS1oEXvp0R"
      },
      "source": [
        "df1.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Uhqo_ydwUhg"
      },
      "source": [
        "df1.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DSQKHmvwtv1"
      },
      "source": [
        "len(df1.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ioiyB7xPg2"
      },
      "source": [
        "df1.summary().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiHqyoYGxRn3"
      },
      "source": [
        "print(df1.schema)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiUfxoHUyNt5"
      },
      "source": [
        "df1.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzNQSebvy4Ne"
      },
      "source": [
        "df1.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKJOw6hzzGRt"
      },
      "source": [
        "df1.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n-aNDk70wHy"
      },
      "source": [
        "df1.crosstab(\"radius_mean\", \"texture_mean\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBLPmQPA080D"
      },
      "source": [
        "cols = [\"radius_mean\", \"texture_mean\"]\n",
        "df1.select(*cols).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElZtbdH1Z-l"
      },
      "source": [
        "df1.selectExpr(\"radius_mean * 2\" , \"texture_mean/3\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpfAnSeGDkYr"
      },
      "source": [
        "df1.selectExpr(\"radius_mean * texture_mean\").alias(\"abcd\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBXkOyN8IWLb"
      },
      "source": [
        "cols = [\"radius_mean\", \"texture_mean\"]\n",
        "df1.sort(*cols).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAAelBKTI_on"
      },
      "source": [
        "df1.take(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZfIzJuiMMRs"
      },
      "source": [
        "df1.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vaQ7eCAMPu0"
      },
      "source": [
        "help(df1.take(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVUWmz1oMTJw"
      },
      "source": [
        "fd = df1.to_koalas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PYQTy0FPEcA"
      },
      "source": [
        "fd['diagnosis'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpesiaVsPO45"
      },
      "source": [
        "grd = fd.groupby('diagnosis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuJgV0O8QFQC"
      },
      "source": [
        "grd['radius_mean'].aggregate(sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs1DEs24QOas"
      },
      "source": [
        "grd['radius_mean'].apply(sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeQfs-3_SAC5"
      },
      "source": [
        "df1.agg({'radius_mean': 'sum'}).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAPE67YTUYn_"
      },
      "source": [
        "grd = df1.groupby('diagnosis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpDjMsX7Uj3n"
      },
      "source": [
        "grd.agg({'radius_mean': 'sum'}).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGdF0l3UvSs"
      },
      "source": [
        "df1.limit(10).select('radius_mean').show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3vw_IpNXp_y"
      },
      "source": [
        "df1.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3am5ei5Y7D1"
      },
      "source": [
        "df1.withColumnRenamed(\"symmetry_se\", \"symmeterySE\").limit(10).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSE9SM5ZK9e"
      },
      "source": [
        "c = [ i.replace(\"_\", \"\") for i in df1.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUZuI4crcLMv"
      },
      "source": [
        "c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0GCJ5vwZs0W"
      },
      "source": [
        "df1.toDF(*c).limit(10).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38oDN8cBao4O"
      },
      "source": [
        "df1.select(*df1.columns[:4]).sort(\"radius_mean\",ascending = False).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6isPpeob9yVg"
      },
      "source": [
        "from pyspark.sql.functions import mean, sumDistinct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrfsnQk2cprC"
      },
      "source": [
        "df1.select(sumDistinct(\"radius_mean\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjWEd3k69wsu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}